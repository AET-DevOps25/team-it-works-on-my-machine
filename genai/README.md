# GenAI Q&A API

A simple FastAPI-based backend for asking questions to a language model (e.g., GPT or DeepSeek), using LangChain for prompt handling and model integration.

---

## ğŸ“ Project Structure

```
genai/                            # Root directory of the GenAI project
â”œâ”€â”€ genai/                        # Python source package (import path: genai.*)
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ input_query/
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze_yaml.py  # YAML analysis logic
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI app entrypoint
â”‚   â”‚   â””â”€â”€ open_api.py          # API routes and OpenAPI integration
â”‚   â”‚
â”‚   â””â”€â”€ rag/                     # Retrieval-Augmented Generation (RAG) modules
â”‚       â”œâ”€â”€ data/                # Processed data for RAG
â”‚       â”œâ”€â”€ ingest/              # Data ingestion logic
â”‚       â”œâ”€â”€ utils/               # Utility functions for RAG
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ test/                        # Unit/integration tests
â”œâ”€â”€ .env                         # Runtime environment variables
â”œâ”€â”€ .env.example                 # Template for .env
â”œâ”€â”€ .python-version              # Python version specification
â”œâ”€â”€ Dockerfile                   # Docker build configuration
â”œâ”€â”€ openapi.json                 # OpenAPI spec (for Swagger or client SDKs)
â”œâ”€â”€ pyproject.toml               # Project configuration & dependencies
â”œâ”€â”€ pytest.ini                   # Pytest configuration
â”œâ”€â”€ uv.lock                      # Lock file (e.g. from `uv` or `poetry`)
â””â”€â”€ README.md                    # Project documentation

```

---

## âš™ï¸ Setup

1. **Create virtual environment (optional but recommended)**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. **Install dependencies**

```bash
pip install uv
uv sync
```

3. **Prepare `.env` file**

Create a `.env` file in the root directory and add:

```env
OPENAI_API_KEY=<your-openai-api-key>

GENAI_PORT=3001
GENAI_URL=http://localhost:${GENAI_PORT}

# Qdrant configuration for vector storage
QDRANT_API_KEY=<your-qdrant-api-key>
QDRANT_URL=<your-qdrant-url>
```

---

## ğŸš€ Run the Server

Make sure you're in the root of the project (`genai/`), then:

```bash
uv run app
```

This starts the FastAPI app at: `http://localhost:3001`

Open your browser at [http://localhost:3001/docs](http://localhost:8000/docs) to test via Swagger UI.
